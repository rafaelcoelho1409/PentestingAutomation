#!/bin/bash
optstring=":hd:f:a:"
export PATH=~/go/bin:~/.cargo/bin:$PATH
TOOLS_PATH=~/TOOLS
URLDEDUPE=~/TOOLS/urldedupe/urldedupe

#---MAIN FUNCTIONS---
SUBFINDER() {
    stage="SUBFINDER"
    banner "RECONNAISSANCE - ${stage}"
    if [[ ! -d "${folder}/subdomains" ]]; then
        mkdir "${folder}/subdomains"
    fi
    subfinder \
        -dL ${domains_file} \
        -o "${folder}/subdomains/subdomains.txt"
    if [[ -e "${folder}/../wildcards.txt" ]]; then
        cat "${folder}/../wildcards.txt" \
            >> "${folder}/subdomains/subdomains.txt"
    fi
}

WAYBACKURLS() {
    stage="WAYBACKURLS"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/subdomains/subdomains.txt" ]]; then
        for subdomain in $(cat "${folder}/subdomains/subdomains.txt"); do
            waybackurls ${subdomain} >> "${folder}/_waybackurls.txt"
        done
        cat "${folder}/_waybackurls.txt" \
            | awk "NF" \
            > "${folder}/waybackurls.txt"
        rm "${folder}/_waybackurls.txt"
    fi
}

HTTPX() {
    stage="HTTPX"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/httpx.txt" ]]; then
        rm "${folder}/httpx.txt"
    fi
    if [[ -e "${folder}/subdomains/subdomains.txt" ]]; then
        cat "${folder}/subdomains/subdomains.txt" \
            | httpx \
                -t 100 \
                -sc -td -ip -title -server -websocket -cname -asn -cdn -probe \
                -o "${folder}/httpx.txt"
        #SUBDOMAINS - PROBE
        cat "${folder}/httpx.txt" \
            | grep -v "FAILED" \
            | grep -oE 'https?://[^ ]+' \
            > "${folder}/subdomains/subdomains_probe.txt"
        #SUBDOMAINS - IPS
        cat "${folder}/httpx.txt" \
            | grep -v "FAILED" \
            | grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b' \
            | awk '!seen[$0]++' \
            | sort \
            > "${folder}/subdomains/subdomains_ips.txt"
        #FILTERING (200, 403 and 4XX STATUS CODES)
        cat "${folder}/httpx.txt" \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | grep -v "FAILED" \
            | awk '!seen[$0]++' \
            | grep "\[200\]" \
            | grep -oE 'https?://[^ ]+' \
            > "${folder}/httpx_200.txt"
        cat "${folder}/httpx.txt" \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | grep -v "FAILED" \
            | awk '!seen[$0]++' \
            | grep "\[403\]" \
            | grep -oE 'https?://[^ ]+' \
            > "${folder}/httpx_403.txt"
        cat "${folder}/httpx.txt" \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | grep -v "FAILED" \
            | awk '!seen[$0]++' \
            | grep "\[4" \
            | grep -oE 'https?://[^ ]+' \
            > "${folder}/httpx_4XX.txt"
    fi
}

DNSREAPER() {
    stage="DNSREAPER"
    banner "RECONNAISSANCE - ${stage}"
    source ${TOOLS_PATH}/virtual_environments/dnsreaper_env/bin/activate
    cd ${TOOLS_PATH}/dnsReaper
    if [[ -e "${folder}/subdomains/subdomains.txt" ]]; then
        python3 main.py file \
            --filename "${folder}/subdomains/subdomains.txt" \
            --out "${folder}/dnsreaper.txt"
    fi
    deactivate
}

DNSX() {
    stage="DNSX"
    banner "RECONNAISSANCE - ${stage}"
    if [[ ! -d "${folder}/dnsx" ]]; then
        mkdir -p "${folder}/dnsx"
    fi
    if [[ -e "${folder}/subdomains/subdomains.txt" ]]; then
        dnsx \
            -l "${folder}/subdomains/subdomains.txt" \
            -recon \
            -o "${folder}/dnsx/dnsx.txt"
        cat "${folder}/dnsx/dnsx.txt" \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | grep -v "\[TXT\]" \
            | grep -v "\[CAA\]" \
            | awk '{ print $3 }' \
            | awk '!seen[$0]++' \
            | sort \
            | sed 's/\[\([^]]*\)\]/\1/g' \
            > "${folder}/dnsx/dnsx_dns.txt"
    fi
}

WEBANALYZE() {
    stage="WEBANALYZE"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/subdomains/subdomains.txt" ]]; then
        webanalyze \
            -hosts "${folder}/subdomains/subdomains.txt" \
            -worker 1000 \
            | tee -a "${folder}/_webanalyze.txt"
        cat "${folder}/_webanalyze.txt" \
            | grep -n '<no results>' \
            | cut -d: -f1 \
            | awk '{ print $0 "\n" $0-1 }' \
            > "${folder}/_webanalyze_lines_to_remove.txt"
        awk 'NR==FNR{lines[$1]; next} !(FNR in lines)' \
            "${folder}/_webanalyze_lines_to_remove.txt" \
            "${folder}_webanalyze.txt" \
            | awk "NF" \
            > "${folder}/webanalyze.txt"
        rm "${folder}/_webanalyze_lines_to_remove.txt"
        rm "${folder}/_webanalyze.txt"


    fi
}

API_DISCOVERY() {
    stage="API_DISCOVERY"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/subdomains/subdomains_probe.txt" ]]; then
        bruteforce_wordlist=${TOOLS_PATH}/SecLists/Discovery/Web-Content/api/api-endpoints.txt
        for subdomain in $(\
            cat "${folder}/httpx.txt" \
                | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
                | grep -v "FAILED" \
                | grep -E '\[2[0-9]{2}\]|\[3(0[2-9]|[1-9][0-9])\]' \
                | awk '{ print $1 }'); do
            subdomain_txt=$(echo "${subdomain}" \
                | sed -e 's|^http://||' -e 's|^https://||')
            time ffuf \
                -u ${subdomain}/FUZZ \
                -w ${bruteforce_wordlist} \
                -t 1000 \
                -s \
                -ignore-body \
                -timeout 5 \
                -fc 404,403,400,503,401,429,301,302,500,204 \
                -o "${folder}/api_discovery_${subdomain_txt}.txt"
            cat "${folder}/api_discovery_${subdomain_txt}.txt" \
                | jq ".results[].url" \
                | tr -d '"' \
                >> "${folder}/_api_discovery.txt"
            results=$(cat "${folder}/_api_discovery.txt" | grep ${subdomain} | wc -l)
            total_words=$(cat ${bruteforce_wordlist} | wc -l)
            percentage=$(python3 -c 'percentage='${results}'/'${total_words}'; print(f"{percentage*100:.2f}")')
            delete=$(python3 -c 'print('${percentage}' > 40.0)')
            if [[ ${delete} == 'True' ]]; then
                echo "${subdomain}: remove results"
            else
                cat "${folder}/_api_discovery.txt" \
                    >> "${folder}/api_discovery.txt"
                echo "${subdomain}: maintain results"     
            fi
            rm "${folder}/_api_discovery.txt"
            rm "${folder}/api_discovery_${subdomain_txt}.txt"
        done
    fi
}

NAABU() {
    stage="NAABU"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/subdomains/subdomains_ips.txt" ]]; then
        naabu -l "${folder}/subdomains/subdomains_ips.txt" \
            -o "${folder}/_naabu.txt"
        cat "${folder}/_naabu.txt" \
            | sort \
            > "${folder}/naabu.txt"
        rm "${folder}/_naabu.txt"
    fi
}

NMAP() {
    stage="NMAP"
    banner "RECONNAISSANCE - ${stage}"
    if [[ ! -d "${folder}/nmap" ]]; then
        mkdir "${folder}/nmap"
    fi
    if [[ -e "${folder}/naabu.txt" ]]; then
        for IP in $(\
            cat "${folder}/subdomains/subdomains_ips.txt"); do
                open_ports=$(\
                    cat "${folder}/naabu.txt" \
                        | grep ${IP} \
                        | awk -F':' '{print $2}')
                open_ports=$(echo ${open_ports} | sed 's/ /,/g')
                nmap -sV -sC -p${open_ports} ${IP} \
                    -oN "${folder}/nmap/${IP}.txt"
                echo "SUBDOMAINS" >> "${folder}/nmap/${IP}.txt"
                cat "${folder}/httpx.txt" \
                    | grep ${IP} \
                    | grep -oE 'https?://[^ ]+' \
                    >> "${folder}/nmap/${IP}.txt"
        done
    fi
}

BRUTEFORCE_SUBDOMAINS() {
    stage="BRUTEFORCE_SUBDOMAINS"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/subdomains/subdomains_probe.txt" ]]; then
        bruteforce_wordlist=${TOOLS_PATH}/SecLists/Discovery/Web-Content/dirsearch.txt
        for subdomain in $(\
            cat "${folder}/httpx.txt" \
                | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
                | grep -v "FAILED" \
                | grep -E '\[2[0-9]{2}\]|\[3(0[2-9]|[1-9][0-9])\]' \
                | awk '{ print $1 }'); do
            subdomain_txt=$(echo "${subdomain}" \
                | sed -e 's|^http://||' -e 's|^https://||')
            time ffuf \
                -u ${subdomain}/FUZZ \
                -w ${bruteforce_wordlist} \
                -t 1000 \
                -s \
                -ignore-body \
                -timeout 5 \
                -fc 404,403,400,503,401,429,301,302,500,204 \
                -o "${folder}/bruteforce_${subdomain_txt}.txt"
            cat "${folder}/bruteforce_${subdomain_txt}.txt" \
                | jq ".results[].url" \
                | tr -d '"' \
                >> "${folder}/_bruteforce_subdomains.txt"
            results=$(cat "${folder}/_bruteforce_subdomains.txt" | grep ${subdomain} | wc -l)
            total_words=$(cat ${bruteforce_wordlist} | wc -l)
            percentage=$(python3 -c 'percentage='${results}'/'${total_words}'; print(f"{percentage*100:.2f}")')
            delete=$(python3 -c 'print('${percentage}' > 40.0)')
            if [[ ${delete} == 'True' ]]; then
                echo "${subdomain}: remove results"
            else
                cat "${folder}/_bruteforce_subdomains.txt" \
                    >> "${folder}/bruteforce_subdomains.txt" 
                echo "${subdomain}: maintain results"    
            fi
            rm "${folder}/_bruteforce_subdomains.txt"
            rm "${folder}/bruteforce_${subdomain_txt}.txt"
        done
    fi
}

DIRECTORIES() {
    stage="DIRECTORIES"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/bruteforce_subdomains.txt" ]]; then
        cat "${folder}/subdomains/subdomains_probe.txt" \
            >> "${folder}/_directories.txt"
        cat "${folder}/bruteforce_subdomains.txt" \
            >> "${folder}/_directories.txt"
        cat "${folder}/_directories.txt" \
            | awk '!seen[$0]++' \
            | sort \
            > "${folder}/directories.txt"
        rm "${folder}/_directories.txt"
    fi
}

KATANA() {
    stage="KATANA"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/directories.txt" ]]; then
        katana \
            -u "${folder}/directories.txt" \
            -silent \
            -o "${folder}/katana.txt"
    fi
}

FINAL_DATA_VERSION() {
    stage="FINAL_DATA_VERSION"
    banner "RECONNAISSANCE - ${stage}"
    if [[ ! -d "${folder}/final_data" ]]; then
        mkdir -p "${folder}/final_data"
    fi
    if [[ -e "${folder}/directories.txt" && -e "${folder}/katana.txt" && -e "${folder}/api_discovery.txt" && -e "${folder}/waybackurls.txt" ]]; then
        cat "${folder}/directories.txt" \
            >> "${folder}/_final_data.txt"
        cat "${folder}/katana.txt" \
            >> "${folder}/_final_data.txt"
        cat "${folder}/api_discovery.txt" \
            >> "${folder}/_final_data.txt"
        #filtering only 200 status code from waybackurls
        #to avoid attack surface to be very wide
        cat "${folder}/waybackurls.txt" \
            | httpx -sc -probe -t 1000 -rstr 0 \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | grep -v "FAILED" \
            | grep "\[200\]" \
            | awk '{ print $1 }' \
            | ${URLDEDUPE} -s \
            > "${folder}/waybackurls_httpx_200.txt"
        cat "${folder}/waybackurls_httpx_200.txt" \
            >> "${folder}/_final_data.txt"
        cat "${folder}/_final_data.txt" \
            | awk '!seen[$0]++' \
            | sort \
            | ${URLDEDUPE} -s \
            > "${folder}/final_data/final_data.txt"    
        rm "${folder}/_final_data.txt"
        #return all status code and probe status by appling httpx
        cat "${folder}/final_data/final_data.txt" \
            | httpx -sc -probe -t 1000 -rstr 0 \
            | grep -v "FAILED" \
            | sort \
            > "${folder}/final_data/_final_data_httpx.txt"
        cat "${folder}/final_data/_final_data_httpx.txt" \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | sort \
            > "${folder}/final_data/final_data_httpx.txt"
        rm "${folder}/final_data/_final_data_httpx.txt"
        #filtering only addresses
        cat "${folder}/final_data/final_data_httpx.txt" \
            | grep -oE 'https?://[^ ]+' \
            | sort \
            > "${folder}/final_data/final_data_httpx_urls.txt"
        #get all discovered requests with parameters
        cat "${folder}/final_data/final_data_httpx_urls.txt" \
            | grep "=" \
            | awk '!seen[$0]++' \
            | ${URLDEDUPE} -s \
            | sort \
            >> "${folder}/requests_with_parameters.txt"
        #get all discovered requests without parameters
        cat "${folder}/final_data/final_data_httpx_urls.txt" \
            | grep -v "=" \
            | awk '!seen[$0]++' \
            | ${URLDEDUPE} -s \
            | sort \
            >> "${folder}/requests_without_parameters.txt"
        #only 403 status code
        cat "${folder}/final_data/final_data_httpx.txt" \
            | grep "\[403\]" \
            | grep -oE 'https?://[^ ]+' \
            | sort \
            > "${folder}/final_data/final_data_httpx_403.txt"
        #only 200 status code
        cat "${folder}/final_data/final_data_httpx.txt" \
            | grep "\[200\]" \
            | grep -oE 'https?://[^ ]+' \
            | sort \
            > "${folder}/final_data/final_data_httpx_200.txt"
        #4XX status code
        cat "${folder}/final_data/final_data_httpx.txt" \
            | grep "\[4" \
            | grep -oE 'https?://[^ ]+' \
            | sort \
            > "${folder}/final_data/final_data_httpx_4XX.txt"
        #EXTENSIONS
        if [[ ! -d "${folder}/final_data/extensions" ]]; then
            mkdir -p "${folder}/final_data/extensions"
        fi
        extensions="js|otf|png|eot|css|svg|mp4|jpg|jpeg|pdf|webp|ttf|woff|woff2|gif|txt"
        #only URLs without extensions
        cat "${folder}/final_data/final_data_httpx_urls.txt" \
            | grep -Ev 'https?://[^/]+/[^"]+\.('${extensions}')' \
            | ${URLDEDUPE} -s \
            | sort \
            > "${folder}/final_data/final_data_httpx_urls_noext.txt"
        #only URLs with extensions
        cat "${folder}/final_data/final_data_httpx_urls.txt" \
            | grep -Eo 'https?://[^/]+/[^"]+\.('${extensions}')' \
            | ${URLDEDUPE} -s \
            | sort \
            > "${folder}/final_data/final_data_httpx_urls_ext.txt"
        #take apart all .js files
        cat "${folder}/final_data/final_data_httpx_urls.txt" \
            | grep -Eo 'https?://[^/]+/[^"]+\.js' \
            | sort \
            > "${folder}/final_data/extensions/js.txt"
        #take apart all .ico files
        cat "${folder}/final_data/final_data_httpx_urls.txt" \
            | grep -Eo 'https?://[^/]+/[^"]+\.ico' \
            | sort \
            > "${folder}/final_data/extensions/ico.txt"
    fi
}

FEROXBUSTER() {
    stage="FEROXBUSTER"
    banner "RECONNAISSANCE - ${stage}"
    if [[ -e "${folder}/subdomains/subdomains_probe.txt" ]]; then
        for subdomain in $(\
            cat "${folder}/subdomains/subdomains_probe.txt"); do
            subdomain_txt=$(echo "${subdomain}" \
                | sed -e 's|^http://||' -e 's|^https://||')
            #DIRSEARCH & RAFT LARGE DIRECTORIES
            feroxbuster \
                -u ${subdomain} \
                -w ${TOOLS_PATH}/bruteforce_wordlist.txt \
                -C 404,403,400,503,401,429 \
                -n \
                -t 1000 \
                -o "${folder}/feroxbuster_${subdomain_txt}.txt" #\
                #--parallel 5
            cat "${folder}/feroxbuster_${subdomain_txt}.txt" | awk '
                /Configuration {/ { 
                    in_block = 1; 
                    brace_count = 1; 
                    next 
                } 
                in_block { 
                    if ($0 ~ /{/) brace_count++; 
                    if ($0 ~ /}/) brace_count--; 
                    if (brace_count == 0) in_block = 0; 
                    next 
                } 
                { print $6 }' \
                >> "${folder}/feroxbuster.txt"   
            rm "${folder}/feroxbuster_${subdomain_txt}.txt" 
        done
        rm ferox-*.state  
    fi
}

SPYHUNT() {
    stage="SPYHUNT"
    banner "RECONNAISSANCE - ${stage}"
    source ${TOOLS_PATH}/virtual_environments/spyhunt_env/bin/activate
    cd ${TOOLS_PATH}/spyhunt
    if [[ -e "${folder}/subdomains/subdomains.txt" ]]; then
        #IMPORTANT SUBDOMAINS
        python3 spyhunt.py -isubs "${folder}/subdomains/subdomains.txt" \
            > "${folder}/subdomains/_important_subdomains.txt"
        cat "${folder}/subdomains/_important_subdomains.txt" \
            | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
            | grep -E '^[0-9]+: .+' \
            | sed 's/^[0-9]\+: //' \
            | awk '!seen[$0]++' \
            | sort \
            > "${folder}/subdomains/important_subdomains.txt"
        rm "${folder}/subdomains/_important_subdomains.txt"
    fi
    deactivate
}

RUSTSCAN() {
    stage="RUSTSCAN"
    banner "RECONNAISSANCE - ${stage}"
    if [[ ! -d "${folder}/rustscan" ]]; then
        mkdir "${folder}/rustscan"
    fi
    if [[ -e "${folder}/httpx.txt" ]]; then
        for IP in $(\
            cat "${folder}/httpx.txt" \
                | grep -v "FAILED" \
                | grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b' \
                | awk '!seen[$0]++' \
                | sort); do
            echo "Scanning ${IP}"
            rustscan -a ${IP} --ulimit 5000 > "${folder}/rustscan/${IP}.txt"
            echo "SUBDOMAINS" >> "${folder}/rustscan/${IP}.txt"
            cat "${folder}/httpx.txt" \
                | grep -v "FAILED" \
                | sed -r 's/\x1B\[[0-9;]*[mK]//g' \
                | grep ${IP} \
                | grep -oE 'https?://[^ ]+' \
                | awk '!seen[$0]++' \
                | sort \
                >> "${folder}/rustscan/${IP}.txt"
        done
    fi
}

#----------------------------------------


#---AUXILIARY FUNCTIONS---
help_function() {
    echo "
    RECONNAISSANCE (R)

    Args:
        Warning: Use only folder name without spacebar
        [-d] File with domains to be scanned
        [-f] Folder to store all data from reconnaissance
        [-a] Choose a specific task to be done
            Options:
            - SUBFINDER
            - WAYBACKURLS
            - HTTPX
            - DNSREAPER
            - DNSX
            - WEBANALYZE
            - API_DISCOVERY
            - NAABU
            - NMAP
            - BRUTEFORCE_SUBDOMAINS
            - DIRECTORIES
            - KATANA
            - FINAL_DATA_VERSION
            - FEROXBUSTER
            - SPYHUNT
            - RUSTSCAN
        [-h] Help"
    exit 0
}   

run_task() {
    if [[ -n ${domains_file} && -n ${folder_init} ]]; then
        ${1}
        exit 0
    else
        echo "Error while running task ${2}"
        exit 1
    fi
}

banner() {
    printf '%*s' 100 | tr ' ' '-'
    echo -e "\n"
    echo -e "${1}\n"
    printf '%*s' 100 | tr ' ' '-'
    echo -e "\n"
}

while getopts ${optstring} options; do
    case ${options} in
        d)
            domains_file="${OPTARG}"
            ;;
        f)
            folder_init="${OPTARG}"
            folder=${folder_init}/Reconnaissance
            if [[ ! -d "${folder}" ]]; then
                mkdir "${folder}"
            fi
            ;;
        a)
            task="${OPTARG}"
            case ${task} in 
                "SUBFINDER")
                    run_task SUBFINDER "SUBFINDER"
                    ;;
                "SPYHUNT")
                    run_task SPYHUNT "SPYHUNT"
                    ;;
                "HTTPX")
                    run_task HTTPX "HTTPX"
                    ;;
                "DNSREAPER")
                    run_task DNSREAPER "DNSREAPER"
                    ;;
                "DIRSEARCH")
                    run_task DIRSEARCH "DIRSEARCH"
                    ;;
                "NMAP")
                    run_task NMAP "NMAP"
                    ;;
                "FEROXBUSTER")
                    run_task FEROXBUSTER "FEROXBUSTER"
                    ;;
                "RUSTSCAN")
                    run_task RUSTSCAN "RUSTSCAN"
                    ;;
                "KATANA")
                    run_task KATANA "KATANA"
                    ;;
                "DIRECTORIES")
                    run_task DIRECTORIES "DIRECTORIES"
                    ;;
                "FINAL_DATA_VERSION")
                    run_task FINAL_DATA_VERSION "FINAL_DATA_VERSION"
                    ;;
                "API_DISCOVERY")
                    run_task API_DISCOVERY "API_DISCOVERY"
                    ;;
                "DNSX")
                    run_task DNSX "DNSX"
                    ;;
                "WAYBACKURLS")
                    run_task WAYBACKURLS "WAYBACKURLS"
                    ;;
                "BRUTEFORCE_SUBDOMAINS")
                    run_task BRUTEFORCE_SUBDOMAINS "BRUTEFORCE_SUBDOMAINS"
                    ;;
                "NAABU")
                    run_task NAABU "NAABU"
                    ;;
                "WEBANALYZE")
                    run_task WEBANALYZE "WEBANALYZE"
                    ;;
                esac
            ;;
        h)
            help_function
            ;;
        ?)
            echo "Error"
            exit 1
            ;;
        esac
    done
#------------------------------